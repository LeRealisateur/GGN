{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664943a-2a31-424b-aef3-36b79d5362a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:42:12.941479Z",
     "start_time": "2024-11-11T11:42:03.361066Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad705af5-21ab-4778-b30e-04a1d53db59d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:42:34.709137Z",
     "start_time": "2024-11-11T11:42:18.400387Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manipulation de données\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Traitement du signal\n",
    "from scipy import signal\n",
    "import mne\n",
    "\n",
    "# Machine Learning et Deep Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import torch\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#import plotly.express as px\n",
    "\n",
    "# Gestion de Notebooks\n",
    "#import papermill as pm\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Utilitaires\n",
    "import joblib\n",
    "import yaml\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Importation code local\n",
    "sys.path.append('preprocessing')\n",
    "import preprocess\n",
    "import dataset\n",
    "import torchcam\n",
    "import models.GGN.ggn_model as GGN\n",
    "import models.GGN.train as train\n",
    "importlib.reload(preprocess)\n",
    "importlib.reload(GGN)\n",
    "importlib.reload(train)\n",
    "importlib.reload(dataset)\n",
    "\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0c9a8",
   "metadata": {},
   "source": [
    "## Chargement de la configuration du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75051ae0-dd5a-4fa5-bfc1-963b87f12360",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:42:37.629398Z",
     "start_time": "2024-11-11T11:42:37.581228Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chargement de la configuration YAML\n",
    "with open(\"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb7966",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175e3f3-a415-4ddd-b5ae-6b7826e73318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T11:42:58.823832Z",
     "start_time": "2024-11-11T11:42:40.477590Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from data/raw/2023_eegpainmarkers_laval/sub-003\\eeg\\sub-003_task-audioactive_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 490000  =      0.000 ...   490.000 secs...\n",
      "Extracting parameters from data/raw/2023_eegpainmarkers_laval/sub-003\\eeg\\sub-003_task-audiopassive_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 490000  =      0.000 ...   490.000 secs...\n",
      "Extracting parameters from data/raw/2023_eegpainmarkers_laval/sub-003\\eeg\\sub-003_task-thermalactive_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 500000  =      0.000 ...   500.000 secs...\n",
      "Extracting parameters from data/raw/2023_eegpainmarkers_laval/sub-003\\eeg\\sub-003_task-thermalpassive_eeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 500000  =      0.000 ...   500.000 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 4 contiguous segments\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('audio'), np.str_('pain')]\n",
      "Not setting metadata\n",
      "494 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 494 events and 4001 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "preprocess.preprocess_data(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c37280",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_model = config['project_config']['running_model']\n",
    "\n",
    "subjects_id = config['data']['subjects']\n",
    "\n",
    "bids_root = config['data']['path']\n",
    "\n",
    "\n",
    "test_losses = []\n",
    "accuracies = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1_scores = []\n",
    "auc_rocs = []\n",
    "\n",
    "if not subjects_id:\n",
    "        subjects_id = [\n",
    "            d for d in os.listdir(bids_root)\n",
    "            if os.path.isdir(os.path.join(bids_root, d)) and d.startswith(\"sub-\")\n",
    "        ]\n",
    "        print(f\"Aucun ID de sujet spécifié. Tous les sujets détectés : {subjects_id}\")\n",
    "\n",
    "for subject in subjects_id:\n",
    "\n",
    "    if running_model == \"GGN\":\n",
    "        train_loader, val_loader, test_loader = dataset.create_dataloader([subject], config)\n",
    "\n",
    "        model = GGN.GGN(**config['models']['GGN']['parameters'], device=device)\n",
    "        \n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        num_epochs = 50\n",
    "\n",
    "        # Train and validate the model\n",
    "        train.train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "        # Test the model\n",
    "        avg_test_loss, accuracy, recall, precision, f1, auc_roc = train.test(model, test_loader, criterion, device)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        accuracies.append(accuracy)\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        f1_scores.append(f1)\n",
    "        auc_rocs.append(auc_roc)\n",
    "        \n",
    "        model.explain_temporal_cnn(test_loader, device)\n",
    "        \n",
    "\n",
    "    elif running_model == \"SVM\":\n",
    "        train_loader, val_loader, test_loader = dataset.create_dataloader([subject], config)\n",
    "\n",
    "        # Convert data loaders to numpy arrays\n",
    "        X_train, y_train = preprocess.dataloader_without_topology_to_numpy(train_loader)\n",
    "        X_val, y_val = preprocess.dataloader_without_topology_to_numpy(val_loader)\n",
    "        X_test, y_test = preprocess.dataloader_without_topology_to_numpy(test_loader)\n",
    "        \n",
    "        print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "        print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "        print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "        # Reshape data\n",
    "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "        X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "        X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "        # Train the SVM\n",
    "        svm_params = config['models']['SVM']['parameters']\n",
    "        svm = SVC(**svm_params)\n",
    "        svm.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        y_val_pred = svm.predict(X_val)\n",
    "        val_acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "        # Test the model\n",
    "        y_test_pred = svm.predict(X_test)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        accuracies.append(test_acc)\n",
    "\n",
    "# Calculate mean test accuracy across all subjects\n",
    "mean_test_loss = np.mean(test_losses)\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "mean_recall = np.mean(recalls)\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "mean_auc_roc = np.mean(auc_rocs)\n",
    "\n",
    "print(f\"Mean Test Loss across all subjects: {mean_test_loss:.4f}\")\n",
    "print(f\"Mean Test Accuracy across all subjects: {mean_accuracy:.2f}%\")\n",
    "print(f\"Mean Recall (Sensitivity) across all subjects: {mean_recall:.2f}\")\n",
    "print(f\"Mean Precision across all subjects: {mean_precision:.2f}\")\n",
    "print(f\"Mean F1 Score across all subjects: {mean_f1:.2f}\")\n",
    "print(f\"Mean AUC-ROC across all subjects: {mean_auc_roc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
